# -*- coding: utf-8 -*-
"""stablediffusion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WzrCLSqxl55NEN3caIdAORKVSanyKzc0
"""

!pip install diffusers transfoemers accelerate scipy safetensors

!huggingface-cli login

# install compatible libs; huggingface-hub<1.0 recommended for older diffusers versions
!pip install -q diffusers transformers accelerate safetensors "huggingface-hub<1.0"

# run in a Colab cell
!hf auth login
# follow the prompt and paste your HF token when requested

import torch
from diffusers import StableDiffusion3Pipeline, StableDiffusionPipeline

device = "cuda" if torch.cuda.is_available() else ("mps" if getattr(torch, "has_mps", False) else "cpu")
print("Device:", device, "torch:", torch.__version__)

# choose dtype: avoid bfloat16 on most GPUs; use float16 on CUDA
dtype = torch.float16 if device == "cuda" else torch.float32

MODEL = "stabilityai/stable-diffusion-3.5-large"
PUBLIC_FALLBACK = "runwayml/stable-diffusion-v1-5"  # public and smaller

try:
    pipe = StableDiffusion3Pipeline.from_pretrained(
        MODEL,
        dtype=dtype,
        use_auth_token=True,   # ensures gated model can be downloaded
    )
    pipe = pipe.to(device)
    print("Loaded SD 3.5 successfully.")
except Exception as e:
    print("Failed to load gated model:", repr(e))
    print("Falling back to a public model:", PUBLIC_FALLBACK)
    # load a public smaller model instead
    pipe = StableDiffusionPipeline.from_pretrained(PUBLIC_FALLBACK, torch_dtype=dtype)
    pipe = pipe.to(device)

# small quick test
prompt = "beautiful greenery forest with birds"
image = pipe(prompt, num_inference_steps=20, guidance_scale=3.5).images[0]
image.save("result.png")
print("Saved result.png")

from IPython.display import display
from PIL import Image

display(Image.open("result.png"))

import torch
from diffusers import StableDiffusion3Pipeline, StableDiffusionPipeline

device = "cuda" if torch.cuda.is_available() else ("mps" if getattr(torch, "has_mps", False) else "cpu")
print("Device:", device, "torch:", torch.__version__)

# choose dtype: avoid bfloat16 on most GPUs; use float16 on CUDA
dtype = torch.float16 if device == "cuda" else torch.float32

MODEL = "stabilityai/stable-diffusion-3.5-large"
PUBLIC_FALLBACK = "runwayml/stable-diffusion-v1-5"  # public and smaller

try:
    pipe = StableDiffusion3Pipeline.from_pretrained(
        MODEL,
        dtype=dtype,
        use_auth_token=True,   # ensures gated model can be downloaded
    )
    pipe = pipe.to(device)
    print("Loaded SD 3.5 successfully.")
except Exception as e:
    print("Failed to load gated model:", repr(e))
    print("Falling back to a public model:", PUBLIC_FALLBACK)
    # load a public smaller model instead
    pipe = StableDiffusionPipeline.from_pretrained(PUBLIC_FALLBACK, torch_dtype=dtype)
    pipe = pipe.to(device)

# small quick test
prompt = "A futuristic city bending into a circular loop in the sky, with floating trams, neon reflections, and clouds swirling through the architecture. Cinematic atmosphere, ultra-detailed, sharp reflections, volumetric lighting."
image = pipe(prompt, num_inference_steps=20, guidance_scale=3.5).images[0]
image.save("result.png")
print("Saved result.png")

from IPython.display import display
from PIL import Image

display(Image.open("result.png"))

import torch
from diffusers import StableDiffusion3Pipeline, StableDiffusionPipeline

device = "cuda" if torch.cuda.is_available() else ("mps" if getattr(torch, "has_mps", False) else "cpu")
print("Device:", device, "torch:", torch.__version__)

# choose dtype: avoid bfloat16 on most GPUs; use float16 on CUDA
dtype = torch.float16 if device == "cuda" else torch.float32

MODEL = "stabilityai/stable-diffusion-3.5-large"
PUBLIC_FALLBACK = "runwayml/stable-diffusion-v1-5"  # public and smaller

try:
    pipe = StableDiffusion3Pipeline.from_pretrained(
        MODEL,
        dtype=dtype,
        use_auth_token=True,   # ensures gated model can be downloaded
    )
    pipe = pipe.to(device)
    print("Loaded SD 3.5 successfully.")
except Exception as e:
    print("Failed to load gated model:", repr(e))
    print("Falling back to a public model:", PUBLIC_FALLBACK)
    # load a public smaller model instead
    pipe = StableDiffusionPipeline.from_pretrained(PUBLIC_FALLBACK, torch_dtype=dtype)
    pipe = pipe.to(device)

# small quick test
prompt = "A warm, friendly robot teaching a class of human children in a sunlit classroom filled with holographic diagrams. Soft bloom lighting, Pixar-style rendering, colorful atmosphere."
image = pipe(prompt, num_inference_steps=20, guidance_scale=3.5).images[0]
image.save("result.png")
print("Saved result.png")

from IPython.display import display
from PIL import Image

display(Image.open("result.png"))

import torch
from diffusers import StableDiffusion3Pipeline, StableDiffusionPipeline

device = "cuda" if torch.cuda.is_available() else ("mps" if getattr(torch, "has_mps", False) else "cpu")
print("Device:", device, "torch:", torch.__version__)

# choose dtype: avoid bfloat16 on most GPUs; use float16 on CUDA
dtype = torch.float16 if device == "cuda" else torch.float32

MODEL = "stabilityai/stable-diffusion-3.5-large"
PUBLIC_FALLBACK = "runwayml/stable-diffusion-v1-5"  # public and smaller

try:
    pipe = StableDiffusion3Pipeline.from_pretrained(
        MODEL,
        dtype=dtype,
        use_auth_token=True,   # ensures gated model can be downloaded
    )
    pipe = pipe.to(device)
    print("Loaded SD 3.5 successfully.")
except Exception as e:
    print("Failed to load gated model:", repr(e))
    print("Falling back to a public model:", PUBLIC_FALLBACK)
    # load a public smaller model instead
    pipe = StableDiffusionPipeline.from_pretrained(PUBLIC_FALLBACK, torch_dtype=dtype)
    pipe = pipe.to(device)

# small quick test
prompt = "A shimmering dragon made of cracked crystals walking across a glowing desert at sunset, light refracting through its body, high-dynamic-range lighting, fantasy character art."
image = pipe(prompt, num_inference_steps=20, guidance_scale=3.5).images[0]
image.save("result.png")
print("Saved result.png")

from IPython.display import display
from PIL import Image

display(Image.open("result.png"))